{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University of Aberdeen\n",
    "\n",
    "## Introduction to Machine Learning and Data-Mining (CS4049)\n",
    "\n",
    "### Tutorial - Reinforcement Learning with OpenAI Gym\n",
    "\n",
    "---\n",
    "\n",
    "The practical is inspired from the code on: https://github.com/ageron/handson-ml/blob/master/16_reinforcement_learning.ipynb\n",
    "\n",
    "\n",
    "## Learning Outcomes\n",
    "\n",
    "On successful completion of this component a student will have demonstrated competence in creating and training an agent to play an Atari game using the screen frames as input\n",
    "\n",
    "### In this tutorial, we will use the following libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For deep neural networks\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "# For data representation\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# For handling files\n",
    "import os\n",
    "\n",
    "# For plotting graphs\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OpenAI Gym\n",
    "import gym\n",
    "env = gym.make(\"Boxing-v0\")\n",
    "# I have installed pyglet-1.5.11 for it work with BigSur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atari Games\n",
    "\n",
    "In this tutorial, we will create an agent to play the Boxing Atari game. In this game, two boxers, one white and one black, compete against each other. When close enough, a boxer can hit his opponent with a punch which causes his opponent to reel back slightly. A match is completed either when one player lands 100 punches or two minutes have elapsed. In the case of a decision, the player with the most landed punches is the winner. Ties are possible. \n",
    "\n",
    "![Activision's Boxing Cartridge](Boxing.png)\n",
    "\n",
    "In this tutorial, we will use the pixels as inputs. The OpenAI Gym environment is `Boxing-v0`. \n",
    "\n",
    "### Naive Agent\n",
    "1.1. For the boxing game, describe the observations, the action space, the reward, the environmentâ€™s info dictionary and the episode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space:  Discrete(18)\n",
      "Observation space: Box([[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]], [[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]], (210, 160, 3), uint8)\n",
      "{'lives': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Action space: \",env.action_space)\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "\n",
    "env.reset()\n",
    "next_obs, reward, done, info = env.step(0)\n",
    "print(info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observation space is an RGB picture of size 210x160 and the action space is composed of the 18 actions that can be performed from an ATARI controller. The info dictionary contains the parameter `ale.lives` which is the number of remaining lives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2. Create a simple agent that performs random actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oliwe\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gym\\envs\\atari\\environment.py:255: UserWarning: \u001b[33mWARN: We strongly suggest supplying `render_mode` when constructing your environment, e.g., gym.make(ID, render_mode='human'). Using `render_mode` provides access to proper scaling, audio support, and proper framerates.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\Oliwe\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward per episode: -0.4\n"
     ]
    }
   ],
   "source": [
    "class RandomAgent():\n",
    "    def __init__(self, env):\n",
    "        self.action_size = env.action_space.n\n",
    "        \n",
    "    def get_action(self, observation):\n",
    "        return random.choice(range(self.action_size))\n",
    "    \n",
    "reward_episodes = []\n",
    "numberOfEpisodes = 10\n",
    "agent = RandomAgent(env)\n",
    "for ep in range(numberOfEpisodes):\n",
    "    current_obs = env.reset()\n",
    "    done = False\n",
    "    total_reward_ep = 0\n",
    "    while not done:\n",
    "        action = agent.get_action(current_obs)\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        total_reward_ep += reward\n",
    "    reward_episodes.append(total_reward_ep)\n",
    "        \n",
    "print(\"Average reward per episode: {}\".format(np.sum(reward_episodes)/numberOfEpisodes))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Q-Learning Agent\n",
    "\n",
    "1.3. Implement a pre-processing function to convert the $210\\times160$ RGB frames to $96\\times80$ greyscale frames. Then, change the type of the matrix to `int8`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "def preprocess_observation(observation):\n",
    "    img = observation[1:192:2, ::2]\n",
    "    img = img.mean(axis=2) #The values or between 0 and 255\n",
    "    img = (img - 128).astype(np.int8) #normalized the values between -128 and 127\n",
    "    return img.reshape(96,80,1)\n",
    "    \n",
    "\n",
    "plt.imshow(obs)\n",
    "plt.show()\n",
    "plt.imshow(preprocess_observation(obs).reshape(96,80), cmap=\"gray\", vmin=-128, vmax = 127)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4. Create a function `q_network` that (1) takes as input a variable of shape $(96,80,1)$, (2) creates a deep convolutional network with 3 convolutional hidden layers and two dense layers, and (3) returns the output layer and the trainable variables in a dictionary where the keys are the name of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_network(X_state, name):\n",
    "    prev_layer = X_state / 128 #the values will be between [-1, 1]\n",
    "    initializer = tf.variance_scaling_initializer()\n",
    "    hidden_activation = tf.nn.relu\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        prev_layer = tf.layers.conv2d(prev_layer, filters=32,\n",
    "                                     kernel_size = 8, strides = 4,\n",
    "                                     padding=\"SAME\", activation= hidden_activation,\n",
    "                                     kernel_initializer = initializer)\n",
    "        prev_layer = tf.layers.conv2d(prev_layer, filters=64,\n",
    "                                     kernel_size = 4, strides = 2,\n",
    "                                     padding=\"SAME\", activation= hidden_activation,\n",
    "                                     kernel_initializer = initializer)\n",
    "        prev_layer = tf.layers.conv2d(prev_layer, filters=64,\n",
    "                                     kernel_size = 3, strides = 1,\n",
    "                                     padding=\"SAME\", activation= hidden_activation,\n",
    "                                     kernel_initializer = initializer)\n",
    "        last_conv_layer_flat = tf.reshape(prev_layer, shape= [-1, 64 * 12*10])\n",
    "        hidden = tf.layers.dense(last_conv_layer_flat, 512,\n",
    "                                activation = hidden_activation, kernel_initializer = initializer)\n",
    "        outputs = tf.layers.dense(hidden, env.action_space.n, kernel_initializer = initializer)\n",
    "    trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope = scope.name)\n",
    "    trainable_vars_by_name = { var.name[len(scope.name):] : var for var in trainable_vars}\n",
    "    return outputs, trainable_vars_by_name\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5. Create an agent `QLearningAgent` with two deep convolutional networks (`online` and `target`) to predict the action to be taken from the game's frames. The `online` network will be trained and replace the `target`network every $5000$ training steps.\n",
    "\n",
    "\n",
    "1.6. Create a method `get_action` using a parameter $\\epsilon$â€¯for making random moves. This parameter will decrease from $1$ to $0.1$.\n",
    "\n",
    "1.7. Create a method `train` to update the weights of the `online` network using the Q-values of the `target` network. We will use a discount rate of $0.99$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent():\n",
    "    def __init__(self, env, learning_rate = 0.001, momemtum = 0.95):\n",
    "        self.action_size = env.action_space.n\n",
    "        self.loss_val = np.infty\n",
    "        tf.reset_default_graph()\n",
    "        tf.disable_eager_execution()\n",
    "        \n",
    "        self.discount_rate = 0.99\n",
    "        \n",
    "        self.checkpoint_path = \"./my_dqn_boxing.ckpt\"\n",
    "        \n",
    "        self.X_state = tf.placeholder(tf.float32, shape= [None, 96, 80, 1])\n",
    "        self.online_q_values, self.online_vars = q_network(self.X_state, name = \"q_networks/online\")\n",
    "        self.target_q_values, self.target_vars = q_network(self.X_state, name = \"q_networks/target\")\n",
    "        \n",
    "        #Define the operations to copy the online network to the target network\n",
    "        self.copy_ops = [ target_var.assign(self.online_vars[var_name]) \n",
    "                         for var_name, target_var in self.target_vars.items()]\n",
    "        self.copy_online_to_target = tf.group(*self.copy_ops)\n",
    "        \n",
    "        # The structure of the training\n",
    "        with tf.variable_scope(\"train\"):\n",
    "            self.X_action = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "            self.q_value = tf.reduce_sum(self.online_q_values * tf.one_hot(self.X_action, self.action_size),\n",
    "                                         axis=1, keepdims = True)\n",
    "            \n",
    "            self.error = tf.abs( self.y - self.q_value) #A value between 0 and infty\n",
    "            self.clipped_error = tf.clip_by_value(self.error, 0.0, 1.0) #If it is above 1 then it becomes 1\n",
    "            self.linear_error = 2 * (self.error - self.clipped_error) \n",
    "            self.loss = tf.reduce_mean(tf.square(self.clipped_error) + self.linear_error)\n",
    "            \n",
    "            self.global_step = tf.Variable(0, trainable = False, name = \"global_step\")\n",
    "            self.optimizer = tf.train.MomentumOptimizer(learning_rate, momentum = momemtum, use_nesterov = True)\n",
    "            self.training_op = self.optimizer.minimize(self.loss, global_step = self.global_step)\n",
    "            \n",
    "        # Saving \n",
    "        self.saver = tf.train.Saver()\n",
    "        self.sess = tf.Session()\n",
    "        if os.path.isfile(self.checkpoint_path + \".index\"):\n",
    "            self.saver.restore(self.sess, self.checkpoint_path)\n",
    "        else:\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            self.sess.run(self.copy_online_to_target)\n",
    "            \n",
    "    def get_action(self, q_values, step):\n",
    "        epsilon = max(0.1, 1 - (0.9/2000000) * step)\n",
    "        if np.random.rand() < epsilon:\n",
    "            return np.random.randint(self.action_size)\n",
    "        else:\n",
    "            return np.argmax(q_values)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def train(self, state_val, action_val, reward, next_state_val, continues):\n",
    "        next_q_values = self.target_q_values.eval(feed_dict={self.X_state : np.array([next_state_val])})\n",
    "        max_next_q_values = np.max(next_q_values , axis = 1, keepdims= True)\n",
    "        #We can now compute the target value\n",
    "        y_val = reward + continues * self.discount_rate *max_next_q_values\n",
    "        _ , self.loss_val = self.sess.run([self.training_op, self.loss], \n",
    "                                         feed_dict= {self.X_state: np.array([state_val]),\n",
    "                                                     self.X_action: np.array([action_val]),\n",
    "                                                     self.y : y_val})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.8. Train your network for $1,000,000$ training steps. Since the training process can take __a lot of time__, save your models every $1000$ training steps. You can choose to only train your model every $4$ frames instead of every frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at S.executeCodeCell (c:\\Users\\Oliwe\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:301742)",
      "at S.execute (c:\\Users\\Oliwe\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:300732)",
      "at S.start (c:\\Users\\Oliwe\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:296408)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (c:\\Users\\Oliwe\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:312326)",
      "at async t.CellExecutionQueue.start (c:\\Users\\Oliwe\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:311862)"
     ]
    }
   ],
   "source": [
    "agent = QLearningAgent(env)\n",
    "\n",
    "\n",
    "n_steps = 1000000\n",
    "copy_steps = 5000\n",
    "save_steps = 1000\n",
    "\n",
    "with agent.sess:\n",
    "    while True:\n",
    "        step = agent.global_step.eval()\n",
    "        if step >= n_steps:\n",
    "            break\n",
    "            \n",
    "            \n",
    "        print(\"\\r\\t Training step {}/{} ({:.1f})% \\t Loss{:5f}\".format(step,n_steps,step*100/ n_steps,agent.loss_val), end=\"\")\n",
    "        \n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "            state = preprocess_observation(obs)\n",
    "            \n",
    "        q_values = agent.online_q_values.eval(feed_dict={\n",
    "            agent.X_state : [state]})\n",
    "        action = agent.get_action(q_values,step)\n",
    "        \n",
    "        #We play the action from the agent\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        next_state = preprocess_observation(next_obs)\n",
    "        agent.train(state, action, reward, next_state, 1.0 - done)\n",
    "        \n",
    "        env.render()\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        if step % copy_steps ==0:\n",
    "            agent.copy_online_to_target.run()\n",
    "        \n",
    "        if step % save_steps ==0:\n",
    "            agent.saver.save(agent.sess, agent.checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.8. Print the evolution of the total number of rewards w.r.t. the episodes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.9. Analyse the behaviour of the saved agents, can you notice any emerging strategies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
